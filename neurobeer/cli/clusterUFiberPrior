#!/usr/bin/env python
""" clusterUFiberPrior

Python command line interface for automated tractography clustering
and evaluation from previously clustered data

"""

def get_parser():
    """
    Argument Parser
    """
    from argparse import ArgumentParser, RawTextHelpFormatter

    parser = ArgumentParser(description='U-fiber extraction and lustering based on clustered data',
                                             formatter_class=RawTextHelpFormatter)

    # Version option
    parser.add_argument('--version', action='version',
                                      version='0.1.3')

    # Required arguments
    g_req = parser.add_argument_group('required arguments')
    g_req.add_argument('--indir', action='store', required=True,
                                      help='the directory with input data')
    g_req.add_argument('--outdir', action='store', required=True,
                                      help='the directory where output files should be stored')
    g_req.add_argument('--subjid', action='store', required=True,
                                      help='subject id to compute')
    g_req.add_argument('--bundle', action='store', required=True,
                                      help='tractography bundle to perform clustering on')
    g_req.add_argument('--prior', action='store', required=True,
                                      help='directory where prior U-fiber data is stored')

    # Optional arguments
    g_opt = parser.add_argument_group('control arguments')
    g_opt.add_argument('-a', action='store', nargs='+', metavar='data',
                                      default=[], help='add scalar data to be used')
    g_opt.add_argument('-w', action='store', nargs='+', metavar='wgt',
                                      default=[], help='provide weighting on data for clustering, ')
    g_opt.add_argument('-sig', action='store', type=float, metavar='sigma',
                                      default=1.0, help='sigma to be used in clustering algorithm')
    g_opt.add_argument('-sall', '--saveAll', action='store_true',
                                      default=False, help='save all similarity matrices')
    g_opt.add_argument('-swt', '--saveWeight', action='store_true',
                                      default=False, help='save weighted similarity matrix')
    g_opt.add_argument('-v', '--verbose', action='count', default=0,
                                      help='verbosity of tool')

    # Performance arguments
    g_prfm = parser.add_argument_group('performance arguments')
    g_prfm.add_argument('-j', action='store', type=int, metavar='nproc',
                                         default=1, help='number of threads')

    return parser

def main():
    """
    Entry point of code
    """
    import os, sys, imp
    sys.path.append(imp.find_module('beer/tractography')[1])
    import numpy as np
    import cluster, fibers, prior, stats, tractio, ufiber

    # Run parser
    opts = get_parser().parse_args()

    # Read input polydata
    indir = os.path.abspath(os.path.join(opts.indir + '/' + opts.subjid))
    outdir = os.path.abspath(os.path.join(opts.outdir + '/' + opts.subjid))

    ptree, ptemp = prior.load(opts.prior)
    pts_per_fiber = ptree.pts_per_fiber
    del ptree, ptemp

    bundleVTK = os.path.join(indir + '/' + opts.bundle)
    bundlePolydata = tractio.readVTK(bundleVTK, opts.verbose)
    fiberData = fibers.FiberTree()
    fiberData.convertFromVTK(bundlePolydata, pts_per_fiber, opts.verbose)
    del bundleVTK

    # Handling scalar data
    scalarDataList = []
    scalarWeightList = []
    scalarTypeList = []
    if opts.a is not None:
        scalarFileList = opts.a
        for DataIdx in scalarFileList:
            path = os.path.join(indir + '/' + str(DataIdx))
            name = path.split('.', -1)[-2]
            name = name.split('/', -1)[-1]
            data = name + 'Data'
            typevar = name + 'Type'
            exec('%s, %s = tractio.readScalar("%s", opts.verbose)' % (data, typevar, path))
            exec('scalarDataList.append(%s)' % (data))
            exec('scalarTypeList.append(%s)' % (typevar))

    if opts.w is not None:
        for val in opts.w:
            scalarWeightList.append(float(val))

    for i in range(len(scalarTypeList)):
        fiberData.addScalar(bundlePolydata, scalarDataList[i], scalarTypeList[i],
                                         fiberData.pts_per_fiber)

    # Extract u-fibers
    uArray, L, D = ufiber.findUFiber(fiberData)
    uFiberTree = ufiber.extractUFiber(fiberData, uArray)
    uFiberTree.copyScalar(fiberData, scalarTypeList, fidxes=uArray)

    # Perform clustering on provided bundle
    outputPolydata, clusterIdx, fiberData, rejIdx = cluster.spectralPriorCluster(
                                    uFiberTree, opts.prior, scalarDataList=scalarDataList,
                                    scalarWeightList=scalarWeightList, scalarTypeList=scalarTypeList,
                                    sigma=opts.sig, saveWSimilarity=opts.saveWeight,
                                    saveAllSimilarity=opts.saveAll, dirpath=outdir, verbose=opts.verbose,
                                    no_of_jobs=opts.j)
    del bundlePolydata, opts.prior, scalarWeightList, scalarDataList

    bundleName = opts.bundle[:-4] + '_uFibers_Clustered.vtk'
    bundledir = os.path.join(outdir, bundleName)
    tractio.writeVTK(outputPolydata, bundledir, opts.verbose)
    clusterData = fiberData.getFibers(range(fiberData.no_of_fibers), rejIdx)
    clusterData = fibers.convertFromTuple(clusterData)
    clusterData.copyScalar(fiberData, scalarTypeList, fidxes=[], rejIdx=rejIdx)

    # NOT USED - SUPPOSE TO EXTRACT STATS FOR COMBINED
    # NEEDS TO BE FIXED FOR USE (IF WANTED/NEEDED)
    # for Type in scalarTypeList:
    #    stats.plotStats(fiberData, Type, dirpath=os.path.join(outdir + '/stats/stats_Clustered'))

    # Extract individual clusters
    for label in np.unique(clusterIdx):
        idxes = np.where(clusterIdx == label)[0]
        bundle = clusterData.getFibers(idxes)
        bundle = fibers.convertFromTuple(bundle)
        polyData = bundle.convertToVTK()
        statsSuffix = 'stats/stats_%i' % label
        statsdir = os.path.join(outdir + '/' + statsSuffix)
        LMean, LStd, DMean, DStd = ufiber.uFiberStats(L, D, idxes, bundle.pts_per_fiber)
        ufiber.writeCSV(LMean, LStd, DMean, DStd, dirpath=outdir)
        print "Avg. fiber length for cluster %i: %.2f +/- %.2f" % (label, LMean, LStd)
        print "Avg. distance between end points for cluster %i: %.2f +/- %.2f" % (label, DMean, DStd)

        for Type in scalarTypeList:
            polyData = cluster.addScalarToVTK(polyData, fiberData, Type, idxes)
            stats.plotStats(clusterData, Type, idxes, dirpath=statsdir)
            stats.writeCSV(clusterData, Type, idxes, dirpath=outdir)

        bundleSuffix = '_uFibers_Cluster%i.vtk' % label
        bundleName = opts.bundle[:-4] + bundleSuffix
        bundledir = os.path.join(outdir + '/' + bundleName)
        tractio.writeVTK(polyData, bundledir, opts.verbose)


if __name__ == '__main__':
    main()
