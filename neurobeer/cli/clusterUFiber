#!/usr/bin/env python
""" clusterUFiber

Python command line interface for automated tractography clustering
and evaluation.

"""

def get_parser():
    """
    Argument Parser
    """
    from argparse import ArgumentParser, RawTextHelpFormatter

    parser = ArgumentParser(description='Tractography extraction and clustering of U-fibers',
                                             formatter_class=RawTextHelpFormatter)

    # Version option
    parser.add_argument('--version', action='version',
                                      version='0.1.3')

    # Required arguments
    g_req = parser.add_argument_group('required arguments')
    g_req.add_argument('--indir', action='store', required=True,
                                          help='the directory with input data')
    g_req.add_argument('--outdir', action='store', required=True,
                                          help='the directory where output files should be stored')
    g_req.add_argument('--subjid', action='store', required=True,
                                      help='subject id to compute')
    g_req.add_argument('--bundle', action='store', required=True,
                                      help='tractography bundle to process')

    # Optional argumentstractograph
    g_opt = parser.add_argument_group('control arguments')
    g_opt.add_argument('-a', action='store', nargs='+', metavar='data',
                                      default=[], help='add scalar data to be used')
    g_opt.add_argument('-w', action='store', nargs='+', metavar='wgt',
                                      default=[], help='provide weighting on data for clustering, ')
    g_opt.add_argument('-p', action='store', type=int, metavar='no_samples',
                                      default=2, help='number of samples to take along each fiber')
    g_opt.add_argument('-k', action='store', type=int, metavar='k_clusters',
                                      default=2, help='number of clusters to use in algorithm')
    g_opt.add_argument('-sig', action='store', type=float, metavar='sigma',
                                      default=1.0, help='sigma to be used in clustering algorithm')
    g_opt.add_argument('-sall', '--saveAll', action='store_true',
                                      default=False, help='save all similarity matrices')
    g_opt.add_argument('-swt', '--saveWeight', action='store_true',
                                      default=False, help='save weighted similarity matrix')
    g_opt.add_argument('-v', '--verbose', action='count', default=0,
                                      help='verbosity of tool')

    # Performance arguments
    g_prfm = parser.add_argument_group('performance arguments')
    g_prfm.add_argument('-j', action='store', type=int, metavar='nproc',
                                         default=1, help='number of threads')

    return parser

def main():
    """
    Entry point of code
    """
    import os, sys, imp
    sys.path.append(imp.find_module('neurobeer/tractography')[1])
    import numpy as np
    import cluster, fibers, stats, tractio, ufiber

    # Run parser
    opts = get_parser().parse_args()

    # Read input polydata
    indir = os.path.abspath(os.path.join(opts.indir + '/' + opts.subjid))
    outdir = os.path.abspath(os.path.join(opts.outdir + '/' + opts.subjid))

    bundleVTK = os.path.join(indir + '/' + opts.bundle)
    bundlePolydata = tractio.readVTK(bundleVTK, opts.verbose)
    fiberData = fibers.FiberTree()
    fiberData.convertFromVTK(bundlePolydata, opts.p, opts.verbose)
    del bundleVTK

    # Handling scalar data
    scalarDataList, scalarWeightList, scalarTypeList = [], [], []
    if opts.a is not None:
        scalarFileList = opts.a
        for DataIdx in scalarFileList:
            path = os.path.join(indir + '/' + str(DataIdx))
            name = path.split('.', -1)[-2]
            name = name.split('/', -1)[-1]
            data = name + 'Data'
            typevar = name + 'Type'
            exec('%s, %s = tractio.readScalar("%s", opts.verbose)' % (data, typevar, path))
            exec('scalarDataList.append(%s)' % (data))
            exec('scalarTypeList.append(%s)' % (typevar))

    if opts.w is not None:
        for val in opts.w:
            scalarWeightList.append(float(val))

    for i in range(len(scalarTypeList)):
        fiberData.addScalar(bundlePolydata, scalarDataList[i], scalarTypeList[i],
                                        fiberData.pts_per_fiber)

    # Extract u-fibers
    uArray, L, D = ufiber.findUFiber(fiberData)
    uFiberTree = ufiber.extractUFiber(fiberData, uArray)
    uFiberTree.copyScalar(fiberData, scalarTypeList, fidxes=uArray, rejIdx=[])

    # Perform clustering on provided bundle
    outputPolydata, clusterIdx, fiberData, rejIdx = cluster.spectralClustering(
                                    uFiberTree, scalarDataList=scalarDataList,
                                    scalarWeightList=scalarWeightList, scalarTypeList=scalarTypeList,
                                    pts_per_fiber=opts.p, k_clusters=opts.k, sigma=opts.sig,
                                    saveWSimilarity=opts.saveWeight, saveAllSimilarity=opts.saveAll,
                                    dirpath=outdir, verbose=opts.verbose, no_of_jobs=opts.j)
    del bundlePolydata, scalarWeightList, scalarDataList

    bundleName = opts.bundle[:-4] + '_uFibers_Clustered.vtk'
    bundledir = os.path.join(outdir, bundleName)
    tractio.writeVTK(outputPolydata, bundledir, opts.verbose)
    clusterData = fiberData.getFibers(range(fiberData.no_of_fibers), rejIdx)
    clusterData = fibers.convertFromTuple(clusterData)
    clusterData.copyScalar(fiberData, scalarTypeList, fidxes=[], rejIdx=rejIdx)

    # NOT USED - SUPPOSE TO EXTRACT STATS FOR COMBINED
    # NEEDS TO BE FIXED FOR USE (IF WANTED/NEEDED)
    # for Type in scalarTypeList:
    #    stats.plotStats(clusterData, Type, dirpath=os.path.join(outdir + '/stats/stats_Clustered'))

    # Extract individual clusters
    for label in np.unique(clusterIdx):
        idxes = np.where(clusterIdx == label)[0]
        bundle = clusterData.getFibers(idxes)
        bundle = fibers.convertFromTuple(bundle)
        polyData = bundle.convertToVTK()
        statsSuffix = 'stats/stats_%i' % label
        statsdir = os.path.join(outdir + '/' + statsSuffix)
        LMean, LStd, DMean, DStd = ufiber.uFiberStats(L, D, idxes)
        ufiber.writeCSV(label, LMean, LStd, DMean, DStd, bundle.no_of_fibers, dirpath=outdir)
        print "Avg. fiber length for cluster %i: %.2f +/- %.2f" % (label, LMean, LStd)
        print "Avg. distance between end points for cluster %i: %.2f +/- %.2f" % (label, DMean, DStd)

        for Type in scalarTypeList:
            polyData = cluster.addScalarToVTK(polyData, clusterData, Type, idxes)
            stats.plotStats(fiberData, Type, idxes, dirpath=statsdir)
            stats.writeCSV(label, fiberData, Type, idxes, dirpath=outdir)

        bundleSuffix = '_uFibers_Cluster%i.vtk' % label
        bundleName = opts.bundle[:-4] + bundleSuffix
        bundledir = os.path.join(outdir + '/' + bundleName)
        tractio.writeVTK(polyData, bundledir, opts.verbose)


if __name__ == '__main__':
    main()
